March 3,2020
Looking at YOLO for object detection, thinking about using remote control to collect data to train a plate detection model.
Created a script to take images from Anki and turn them into videos for later analysis

March 5
Planning on using SIFT to detect the "Cars" and cut away that part of the image
Update after working with SIFT, now trying to use HSV colors to detect the block. Finding more success and will need to get the
HSV colors for each block. Afterward I will develop an algorithm to isolate the plates. Requires more thinking

March 12
New license labels might make it easier to detect the location from the images. I will try to get SIFT to detect the 'car' block
since I haven't had success using SIFT to isolate the plates themselves. I want to use SIFT to isolate the cars and then splice the
image to then look for the plates. Currently I have been using HSV to isolate blocks in the images.

I've gotten a bounding box on the 'car' blocks after converting the HSV images to binary and analyzing the amount of pixels in the 
frame vertical and horizontally. This only works if there's one car in the image.
My next task is to allow for the detection of multiple 'cars'. I'm thinking of imlpementing an algorithm to
detect rises and falls in the binary image.

Spent some time on the updated course collecting more data. Going to update our PID drive to include recording video.

March 30
Change of plans to work on simulation now instead. Going to first work on manually controlling the simulation robot in Gazebo and have that record video to be analyzed so I
can adapt the previous work into something usable for sim

Goals for today are:
Implement video capture from manual driving
Look at the video and transfer the algorithm from real world onto sim
Isolate license plates

After working on this for 6 hours I have successfully implemented a video capture script off the simulated robot and saving them to a video folder to develop an
algorithm to cut away the license plates.

Adjusting some hsv values I have managed to get a bounding box around the cars and cut away those images to them be analyzed for the license plates.
We can now focus on cropping out the license plates to be fed into a neural net for later which I will work on later this week.

Some issues i'm seeing right now are the time it takes to analyze one frame so I will likely limit the analysis of frames to every 10 or 30 and only
once the bounding box around the car is large enough for a clear view of the plates. It would also be ideal to only look at a specific section of the
frame lowering the number of pixels I would need to look at.

April 2
Today I plan on speeding up the analysis of images, focussing on the right half of the image, this should also remove issues with seeing two cars in one image as we want to
focus on the larger and clearer image rather than the one farther back.

Goals and Tasks:
Determine a good size to crop the image down to before using OpenCV
Implement vision for all three colours of cars
Isolate the license plates into their own image to be stored
Differentiate parking number with plate number
Begin work on neural network by collecting data from these plates from the robot driving
Integrate PID with Alex's part of the codebase

Notes:
Simulated world coordinates in Gazebo
Start location with blue cars: x -2.2 y -2.4 z 0.05 R 0.0 P 0.0 Y 1.57
Corner with green cars: x 2.2 -y 2.4 z 0.05 R 0.0 P 0.0 Y 1.57